{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8299da",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "A Support Vector Machine (SVM) is capable of performing:\n",
    "- linear or nonlinear classification\n",
    "- regression\n",
    "- outlier detection\n",
    "\n",
    "SVMs are well suited for classification of complex small- or medium-sized datasets.\n",
    "\n",
    "SVMs are sensitive to the feature scales.\n",
    "\n",
    "If SVM model is overfitting, you can try regularizing it by reducing C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd24b09",
   "metadata": {},
   "source": [
    "### Section 1: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e123d88",
   "metadata": {},
   "source": [
    "#### Linear SVM Classification\n",
    "- hard margin classification (not working well when there are outliers) \n",
    "- soft margin classification (not working well when classes are not linearly separable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba458e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d531c294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64) # Iris virginica\n",
    "svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "])\n",
    "svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced5a00",
   "metadata": {},
   "source": [
    "#### Nonlinear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3d65f",
   "metadata": {},
   "source": [
    "One approach to handling nonlinear datasets is to add more features, such as polynomial features; in some cases this can result in a linearly separable dataset.\n",
    "\n",
    "That said, at a low polynomial degree, this method cannot deal with very complex datasets, and with a high polynomial degree it creates a huge number of features, making the model too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1869cde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tduan\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X, y = make_moons(n_samples=100, noise=0.15)\n",
    "polynomial_svm_clf = Pipeline([\n",
    "(\"poly_features\", PolynomialFeatures(degree=3)),\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", LinearSVC(C=10, loss=\"hinge\"))\n",
    "])\n",
    "polynomial_svm_clf.fit(X, y); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9339a050",
   "metadata": {},
   "source": [
    "Fortunately, when using SVMs you can apply an almost miraculous mathematical technique called the kernel trick (explained in a moment). The kernel trick makes it possible to get the same result as if you had added many polynomial features, even with very high-degree polynomials, without actually having to add them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601abdc",
   "metadata": {},
   "source": [
    "#### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc61dfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
    "])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd1bb8",
   "metadata": {},
   "source": [
    "#### Gaussian RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f9f70c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbf_kernel_svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd492e",
   "metadata": {},
   "source": [
    "As a rule of thumb, you should always try the linear kernel first (remember that LinearSVC is much faster than SVC(kernel=\"linear\")), especially if the training set is very large or if it\n",
    "has plenty of features. \n",
    "\n",
    "If the training set is not too large, you should also try the Gaussian RBF kernel; it works well in most cases. \n",
    "\n",
    "Then if you have spare time and computing power, you can experiment with a few other kernels, using cross-validation and grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087cf3ca",
   "metadata": {},
   "source": [
    "### Section 2: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092673ea",
   "metadata": {},
   "source": [
    "#### Linear SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa62556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(epsilon=1.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svm_reg = LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ffda37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd04b7e",
   "metadata": {},
   "source": [
    "#### Non-Linear SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59eec5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, degree=2, kernel='poly')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "svm_poly_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fbf05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
